id: Transformers-en-to-vi
seed: 2104
pretrained_path: null
model:
    d_model: 512
    d_ffn: 2048
    n_layer: 6
    n_head: 8
    max_len: 256
    dropout: 0.1
trainer:
    nepochs: 50
    val_step: 1
    log_step: 30
    lr: !!float 1e-4
optimizer:
    # adam_eps: !!float 1e-8
    patience: 10
    warmup: 10
    # clip: 1.0
    factor: 0.5
dataset:
    root_dir: ./data/en-vi/processed-data
    train:
        batch_size: 16
        shuffle: True
        clip_grads: False
        num_workers: 8
    val:
        batch_size: 16
        num_workers: 8
